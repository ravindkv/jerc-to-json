jerc2json
========

This is a Python package for generating and validating `correctionlib` JSON files
for jet energy calibration, using the text files in the traditional Jet Energy Resolution
and Corrections (JERC) format as inputs.

The `jerc2json` package helps you:
- retrieve the relevant JERC text files from their repositories
- create equivalent JSON calibration files for use with `correctionlib`, and
- validate the resulting JSON files using several methods

**Acknowledgement**: Many thanks to Henning Kirschenmann for providing the bulk of
the code for the textfile-to-JSON conversion and implementing the JER smearing
functionality.

**Note**: this tool only supports Python 3. Python 2 support will not be added.

**Note**: this package is still in active development and some features or interfaces
may change with little to no prior notice.


Requirements
------------

This tool should be used with Python version 3.9 and above.

To read the JERC text files, CMSSW and nanoAOD-tools are required. Assuming CVMFS
is available, the following setup using CMSSW version `CMSSW_12_4_11_patch3`
is known to work:

```bash
source /cvmfs/cms.cern.ch/cmsset_default.sh
scramv1 project CMSSW CMSSW_12_4_11_patch3
cd CMSSW_12_4_11_patch3/src
eval `scramv1 runtime -sh`
git clone https://gitlab.cern.ch/cms-jetmet/jerc2json
git clone https://github.com/cms-nanoAOD/nanoAOD-tools.git PhysicsTools/NanoAODTools
scramv1 build
cd $CMSSW_BASE/src/jerc2json
```

**Important note**: To read and write the JSON files, `correctionlib` is required. While
newer versions of CMSSW already ship with `correctionlib`, the version contained therein
might be outdated. For best results, it is recommended to install a recent version of
`correctionlib` inside the CMSSW environment. This can be done by sourcing the
`install_correctionlib_cmssw.sh` script provided as part of this repository.

Other required packages, including minimal recommended versions, are documented in
`requirements.txt`.

Quickstart
----------

To get started with generating JSON files, let's use the default config, `config.yml`.
Pick an era from that config (here we will use `Run2Summer20UL18`), and start by
downloading the tarballs containing the JERC text files via the `get` subcommand:
```bash
python3 -m jerc2json get --eras Run2Summer20UL18
```

You will see messages like the following one, indicating that the correction tarballs
have been downloaded and extracted to the *work directory* (this is `work` by default,
but this can be changed in the config):
```
Downloading tarball: https://github.com/cms-jet/JRDatabase/raw/master/tarballs/Summer19UL18_JRV2_MC.tar.gz
Extracting tarball: work/Summer19UL18_JRV2_MC.tar.gz
```

Next, JSON files can be generated by running the `create` subcommand:
```bash
python3 -m jerc2json create --eras Run2Summer20UL18
```

The JSON files are located in the *output directory* (`json_files` by default), in
subdirectories corresponding to the era name:
```
...
Wrote output file: json_files/Run2Summer20UL18/jet_jerc.json
Wrote output file: json_files/Run2Summer20UL18/jet_jerc.json.gz
Wrote output file: json_files/Run2Summer20UL18/fatJet_jerc.json
Wrote output file: json_files/Run2Summer20UL18/fatJet_jerc.json.gz
```

To validate the JSON files, we compare the values obtained using `correctionlib` with
these files to the ones obtained from CMSSW using the original JERC text files. A simple
comparison, performed by simply picking a few values for the input variables and
comparing the results, can be done using the `validate` subcommand:
```bash
python3 -m jerc2json validate --eras Run2Summer20UL18
```

This should produce validation results, which are stored in YAML files alongside the
produced JSON files:
```
...
Wrote validation results to file: json_files/Run2Summer20UL18/jet_jerc.validation_simple.yml
Wrote validation results to file: json_files/Run2Summer20UL18/fatJet_jerc.validation_simple.yml
```

Here is a (simplified) example of the YAML file contents:
```yaml
Summer19UL18_JRV2_MC_PtResolution_AK4PFchs:
  input_vars:
   - name: JetEta
     values:
     - 0.1
   - name: JetPt
     values:
     - 200.0
   - name: Rho
     values:
     - 20.0
  correction_values_stats:
    diff:
      count: 1.0
      mean: -9.073374690471425e-10
      ...
```

For each correction stored in the JSON file (`Summer19UL18_JRV2_MC_PtResolution_AK4PFchs`
in the example above), the `input_vars` and the corresponding values used for the
validation are listed. The `correction_values_stats` key contains the results of evaluating
several statistical functions over the correction values. `diff` here refers to the difference
between the values obtained from the JSON file via `correctionlib` and the corresponding
values obtained from the JERC text files via CMSSW. The value `count: 1.0` indicated that
the corrections were evaluated on a single point, and the `mean` value of `-9e-10` indicates
that the JSON and CMSSW values are nearly identical.

A more elaborate validation can be done by passing the parameter `--validation-type`. For
example, passing `grid` will use the binning information stored in the JSON file to compute
a multidimensional grid of input values and evaluate the correction at each grid point:
```bash
$ python3 -m jerc2json validate --eras Run2Summer20UL18 --validation-type grid
...
Wrote validation results to file: json_files/Run2Summer20UL18/jet_jerc.validation_grid.yml
```

If we look at the indicated YAML file, we see that multiple input values have now been generated:
```yaml
Summer19UL18_JRV2_MC_PtResolution_AK4PFchs:
  input_vars:
  - name: JetEta
    values:
    - -5.075
    - -4.7
    - -4.325
    - -3.2
    ...
  correction_values_stats:
    diff:
      count: 19635.0
      mean: -3.2323998710390064e-10
      ...
```

The total number of grid points is indicated by `count: 19635.0`, and the average difference
between the `correctionlib` and CMSSW values in this case is again very small at around `-3e-10`,
indicating a very good closure.

Finally, we can visualize the information in the YAML files by calling `plot_validation` with
the same arguments:
```bash
$ python3 -m jerc2json plot_validation --config config_test.yml --eras Run2Summer20UL18 --validation-type grid
...
Saved validation plot to: json_files/Run2Summer20UL18/jet_jerc.validation_grid.0.png
```

This will produce a plot showing the statistical indicators visually for all corrections.


Configuration structure
-----------------------

Most of the information needed to generate JSON files is contained in the configuration file.
The default configuration file is `config.yml` which can be adapted to suit your needs. Comments
are provided in `config.yml` to document how the configuration is structured.

A key piece of the configuration is the `eras` entry, wherein the JEC and JER versions to be
merged into the final JSON file(s) is specified. At the time of writing, the following is a valid
configuration example for generating JSON files with JEC and JER information for 2018 Ultra-Legacy
samples:

```yaml
# eras for which to provide JSON files
eras:
  Run2Summer20UL18:
    jec:
      names:
      - Summer19UL18_V5_MC
      - Summer19UL18_RunA_V5_DATA
      - Summer19UL18_RunB_V5_DATA
      - Summer19UL18_RunC_V5_DATA
      - Summer19UL18_RunD_V5_DATA
    jer:
      names:
      - Summer19UL18_JRV2_MC
```

:todo: Finish section
